# ADK Testing Guide for Multi-Agent System

## Quick Start

### Option 1: Using the Test Script
```bash
./test_adk.sh
```

This will:
- Activate your virtual environment
- Start ADK web interface on port 8000
- Show available agents

### Option 2: Manual ADK Command
```bash
# Activate virtual environment
source .venv/bin/activate  # or: source venv/bin/activate

# Start ADK web interface
adk web --port 8000
```

## Available Agents

Once ADK web interface opens, you'll see these agents:

### 1. **utsava_sathi_festival_planner** (Single Agent)
- **Location**: `utsava_agent.agent.root_agent`
- **Description**: Legacy single agent that handles everything
- **Use Case**: Compare with multi-agent system

### 2. **utsava_coordinator** (Multi-Agent Coordinator) ‚≠ê
- **Location**: `utsava_agent.coordinator.coordinator_agent`
- **Description**: Orchestrates all specialized agents
- **Use Case**: Test the full multi-agent system
- **Tools Available**:
  - `call_research_agent` - Calls research specialist
  - `call_preparation_agent` - Calls preparation specialist
  - `call_experience_agent` - Calls experience specialist
  - `call_content_agent` - Calls content specialist
  - `google_search` - For validation

### 3. **festival_research_agent** (Specialized)
- **Location**: `utsava_agent.agents.research_agent.research_agent`
- **Description**: Researches festival overview
- **Use Case**: Test individual agent

### 4. **festival_preparation_agent** (Specialized)
- **Location**: `utsava_agent.agents.preparation_agent.preparation_agent`
- **Use Case**: Test individual agent

### 5. **festival_experience_agent** (Specialized)
- **Location**: `utsava_agent.agents.experience_agent.experience_agent`
- **Use Case**: Test individual agent

### 6. **festival_content_agent** (Specialized)
- **Location**: `utsava_agent.agents.content_agent.content_agent`
- **Use Case**: Test individual agent

## Testing the Coordinator Agent

### Step 1: Select Agent
In ADK web interface:
1. Select the **`utsava_agent`** app
2. Choose **`utsava_coordinator`** agent

### Step 2: Test Request
Try this example prompt:
```
Plan Nuakhai in Bhubaneswar for a family of 3 with one small child.
```

### Step 3: Observe Agent Calls
In the ADK interface, you should see:
1. Coordinator receives the request
2. Coordinator calls `call_research_agent` tool
3. Coordinator calls `call_preparation_agent` tool
4. Coordinator calls `call_experience_agent` tool
5. Coordinator calls `call_content_agent` tool
6. Coordinator assembles final JSON

### Step 4: Verify Output
The final response should be a complete FestivalPlan JSON with:
- `festival_overview` (from research agent)
- `pre_festival` (from preparation agent)
- `festival_day` (from experience agent)
- `shareables` (from content agent)
- `metadata` (generated by coordinator)

## Testing Individual Agents

You can also test each specialized agent individually:

### Research Agent
```
Research Nuakhai in Bhubaneswar. Return festival_overview JSON.
```

Expected output:
```json
{
  "name": "Nuakhai",
  "local_name": "Nuakhai Parab",
  "why_celebrated": "...",
  "short_story": "...",
  "themes": [...]
}
```

### Preparation Agent
```
Plan pre-festival activities for Nuakhai in Bhubaneswar for family of 3 with one child. Return pre_festival JSON.
```

### Experience Agent
```
Plan festival day experience for Nuakhai in Bhubaneswar for family of 3 with one child. Return festival_day JSON.
```

### Content Agent
```
Create shareable content. Puja items: ["Rice", "Fruits", "Flowers"]. Tasks: ["Clean house", "Buy clothes"]. Return shareables JSON.
```

## Troubleshooting

### Agent Not Found
If an agent doesn't appear in ADK:
1. Check that the agent is properly exported in `__init__.py`
2. Verify Python path includes the project root
3. Restart ADK web interface

### Tool Call Errors
If agent-to-agent calls fail:
1. Check logs for "AGENT_TOOL_CALL" messages
2. Verify all agents are properly initialized
3. Check that API key is set in `.env`

### JSON Parsing Errors
If JSON extraction fails:
1. Check agent responses in ADK event viewer
2. Verify agents return valid JSON
3. Check `agent_tool.py` extraction logic

## Comparing Single vs Multi-Agent

### Single Agent Test
1. Select `utsava_sathi_festival_planner`
2. Use same prompt: "Plan Nuakhai in Bhubaneswar for a family of 3"
3. Note response time and quality

### Multi-Agent Test
1. Select `utsava_coordinator`
2. Use same prompt
3. Observe:
   - Multiple tool calls
   - Specialized responses
   - Final assembly
   - Response time

### Comparison Points
- **Response Quality**: More specialized vs general
- **Response Time**: May be longer due to multiple calls
- **Debugging**: Easier to see which part failed
- **Modularity**: Can update individual agents

## Advanced Testing

### Test Parallel Execution
The coordinator can call research, preparation, and experience agents in parallel (if ADK supports it). Check the execution timeline in ADK.

### Test Error Handling
Try invalid requests to see how agents handle errors:
- Unknown festival name
- Missing location
- Invalid family context

### Test Edge Cases
- Very long prompts
- Multiple festivals mentioned
- Unclear location
- Missing family context

## Logs and Debugging

ADK web interface shows:
- Agent execution timeline
- Tool calls and responses
- Intermediate results
- Final output

Check the browser console and ADK logs for:
- `AGENT_TOOL_CALL` - When coordinator calls an agent
- `AGENT_TOOL_SUCCESS` - When agent returns successfully
- `AGENT_TOOL_ERROR` - When agent call fails

## Next Steps

After testing:
1. Compare results between single and multi-agent
2. Optimize agent prompts based on results
3. Add caching for common festivals
4. Improve error handling
5. Add validation at each step

